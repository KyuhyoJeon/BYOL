{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BYOL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFO42TpCu4GKbtbbdnT5oK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyuhyoJeon/BYOL/blob/master/BYOL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNSucA50ncE3"
      },
      "source": [
        "import easydict\r\n",
        "\r\n",
        "args = easydict.EasyDict({\r\n",
        "    'name':'byol_cifar_experiment', \r\n",
        "    'backbone':'resnet50', \r\n",
        "    'num_epochs':1000, \r\n",
        "    'warmup_epochs':10, \r\n",
        "    'base_lr':0.2, \r\n",
        "    'weight_decay':1.5e-6, \r\n",
        "    'base_tau':0.996, \r\n",
        "    'checkpoint_epochs':5, \r\n",
        "    'optim_name':'lars', \r\n",
        "    'eval':True, \r\n",
        "    'eval_optim_name':'sgd', \r\n",
        "    'data':easydict.EasyDict({\r\n",
        "        'image_size':224, \r\n",
        "        'batch_size':4096, \r\n",
        "        'num_workers':8, \r\n",
        "        'dir':'./data',   \r\n",
        "    }), \r\n",
        "    'knn':easydict.EasyDict({\r\n",
        "        'monitor':True, \r\n",
        "        'interval':5, \r\n",
        "        'k':200\r\n",
        "    }), \r\n",
        "    'mlp':easydict.EasyDict({\r\n",
        "        'hidden_size':4096, \r\n",
        "        'projection_size':256, \r\n",
        "    }), \r\n",
        "    'ckpt_dir':'./ckpt',\r\n",
        "    'device':'cuda', \r\n",
        "    'bn_decay_rate':0.9, \r\n",
        "    'bn_eps':1e-5, \r\n",
        "    'seed':1337, \r\n",
        "    'dryrun':True, \r\n",
        "    'debug':True\r\n",
        "})\r\n",
        "\r\n",
        "if args.dryrun:\r\n",
        "  args.data.image_size=32\r\n",
        "  args.num_epochs = 10\r\n",
        "  args.data.batch_size = 256\r\n",
        "  args.num_workers=0\r\n",
        "  args.dryrun_subset_size = 100\r\n",
        "  args.backbone = 'resnet18'\r\n",
        "\r\n",
        "if args.debug:\r\n",
        "  args.image_size=32\r\n",
        "  args.num_epochs = 1\r\n",
        "  args.warmup_epochs = 1\r\n",
        "  args.data.batch_size = 2\r\n",
        "  args.data.num_workers = 0\r\n",
        "  args.debug_subset_size = 8\r\n",
        "  args.backbone = 'resnet18'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwAPPgDwNo2j"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, transforms\r\n",
        "\r\n",
        "class simclr_transform:\r\n",
        "  # augmentations: \r\n",
        "  # random patch, 224 resize, random hrizontal flip, color distortion, \r\n",
        "  # random swquence brightness, contrast, saturation, hue adjustment, \r\n",
        "  # and optional gray scale conversion, Gaussian blur, solarization\r\n",
        "  imagenet_mean_std = [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\r\n",
        "  def __init__(self, size, mean_std=imagenet_mean_std, s=1.0):\r\n",
        "    self.transform = transforms.Compose(\r\n",
        "        [\r\n",
        "        transforms.RandomSizedCrop(size=size), \r\n",
        "        transforms.RandomHorizontalFlip(), \r\n",
        "        transforms.RandomApply(\r\n",
        "            [transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)], p=0.8),\r\n",
        "        transforms.RandomGrayscale(p=0.2),\r\n",
        "        transforms.RandomApply(\r\n",
        "            [transforms.GaussianBlur(kernel_size=size//20*2+1, sigma=(0.1, 2.0))], p=0.5), \r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize(*mean_std)\r\n",
        "        ]\r\n",
        "    )\r\n",
        "  def __call__(self, x):\r\n",
        "    x1 = self.transform(x)\r\n",
        "    x2 = self.transform(x)\r\n",
        "    return x1, x2\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "class Transform_single():\r\n",
        "  imagenet_mean_std = [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\r\n",
        "  def __init__(self, size, train, normalize=imagenet_mean_std):\r\n",
        "    if train == True:\r\n",
        "      self.transform = transforms.Compose(\r\n",
        "          [\r\n",
        "           transforms.RandomResizedCrop(size, scale=(0.08, 1.0), \r\n",
        "                                        ratio=(3.0/4.0,4.0/3.0), \r\n",
        "                                        interpolation=Image.BICUBIC\r\n",
        "                                        ),\r\n",
        "           transforms.RandomHorizontalFlip(),\r\n",
        "           transforms.ToTensor(),\r\n",
        "           transforms.Normalize(*normalize)\r\n",
        "          ]\r\n",
        "      )\r\n",
        "    else:\r\n",
        "      self.transform = transforms.Compose(\r\n",
        "          [\r\n",
        "           transforms.Resize(int(size*(8/7)), \r\n",
        "                             interpolation=Image.BICUBIC\r\n",
        "                             ), # 224 -> 256 \r\n",
        "           transforms.CenterCrop(size),\r\n",
        "           transforms.ToTensor(),\r\n",
        "           transforms.Normalize(*normalize)\r\n",
        "          ]\r\n",
        "      )\r\n",
        "\r\n",
        "  def __call__(self, x):\r\n",
        "    return self.transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5jUb9pev062",
        "outputId": "2f1d38c7-362c-49d8-fd5d-55fd8eef1c5e"
      },
      "source": [
        "cifar_train = datasets.CIFAR10(\r\n",
        "    root=args.data.dir, \r\n",
        "    train=True, \r\n",
        "    transform=simclr_transform(args.data.image_size), \r\n",
        "    download=True\r\n",
        ")\r\n",
        "\r\n",
        "cifar_memory = datasets.CIFAR10(\r\n",
        "    root=args.data.dir, \r\n",
        "    train=True, \r\n",
        "    download=False, \r\n",
        "    transform=Transform_single(size=args.data.image_size, train=False), \r\n",
        "    )\r\n",
        "\r\n",
        "cifar_test = datasets.CIFAR10(\r\n",
        "    root=args.data.dir, \r\n",
        "    train=False, \r\n",
        "    download=False, \r\n",
        "    transform=Transform_single(size=args.data.image_size, train=False), \r\n",
        ")\r\n",
        "\r\n",
        "if args.debug:\r\n",
        "  cifar_train = torch.utils.data.Subset(cifar_train, range(0, args.debug_subset_size))\r\n",
        "  cifar_train.classes = cifar_train.dataset.classes\r\n",
        "  cifar_train.targets = cifar_train.dataset.targets\r\n",
        "  cifar_memory = torch.utils.data.Subset(cifar_memory, range(0, args.debug_subset_size))\r\n",
        "  cifar_memory.classes = cifar_memory.dataset.classes\r\n",
        "  cifar_memory.targets = cifar_memory.dataset.targets\r\n",
        "  cifar_test = torch.utils.data.Subset(cifar_test, range(0, args.debug_subset_size))\r\n",
        "  cifar_test.classes = cifar_test.dataset.classes\r\n",
        "  cifar_test.targets = cifar_test.dataset.targets\r\n",
        "# elif args.dryrun:\r\n",
        "#   cifar_train = torch.utils.data.Subset(cifar_train, range(0, args.dryrun_subset_size))\r\n",
        "#   cifar_train.classes = cifar_train.dataset.classes\r\n",
        "#   cifar_train.targets = cifar_train.dataset.targets\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    cifar_train, \r\n",
        "    batch_size=args.data.batch_size, \r\n",
        "    shuffle=True, \r\n",
        "    num_workers=args.data.num_workers, \r\n",
        "    drop_last=True, \r\n",
        "    pin_memory=True\r\n",
        ")\r\n",
        "\r\n",
        "memory_loader = torch.utils.data.DataLoader(\r\n",
        "    cifar_memory, \r\n",
        "    shuffle=False,\r\n",
        "    batch_size=args.data.batch_size,\r\n",
        "    num_workers=args.data.num_workers,\r\n",
        "    drop_last=True,\r\n",
        "    pin_memory=True,\r\n",
        "    )\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    cifar_test, \r\n",
        "    shuffle=False,\r\n",
        "    batch_size=args.data.batch_size,\r\n",
        "    num_workers=args.data.num_workers,\r\n",
        "    drop_last=True,\r\n",
        "    pin_memory=True,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:841: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
            "  \"please use transforms.RandomResizedCrop instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sSKUET0IL1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "cd7c3ce1-fb6f-4eea-b282-77e044babeda"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def imshow(img):\r\n",
        "  img = img / 2 + 0.5     # unnormalize\r\n",
        "  npimg = img.numpy()\r\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "dataiter = iter(train_loader)\r\n",
        "(images1, images2), labels = dataiter.next()\r\n",
        "\r\n",
        "imshow(torchvision.utils.make_grid(images1))\r\n",
        "imshow(torchvision.utils.make_grid(images2))\r\n",
        "print(' '.join('%5s' % train_loader.dataset.classes[labels[j]] for j in range(len(labels))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "truck automobile\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh_OjbkTKGV-"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "from torchvision import models\r\n",
        "\r\n",
        "if args.backbone is not None:\r\n",
        "  resnet = eval(f'models.{args.backbone}()')\r\n",
        "  # resnet = eval(f\"{backbone_name}()\")\r\n",
        "  resnet.output_dim = resnet.fc.in_features\r\n",
        "  resnet.fc = nn.Identity()\r\n",
        "else:\r\n",
        "  raise NotImplementedError(\"Backbone is not implemented!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDkTLBPcy1lv"
      },
      "source": [
        "import copy\r\n",
        "import math\r\n",
        "from torch.nn import functional\r\n",
        "\r\n",
        "class MLP(nn.Module):\r\n",
        "  def __init__(self, input_dim):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.net = nn.Sequential(\r\n",
        "        nn.Linear(input_dim, args.mlp.hidden_size), \r\n",
        "        nn.BatchNorm1d(args.mlp.hidden_size, momentum=1-args.bn_decay_rate, eps=args.bn_eps), \r\n",
        "        nn.ReLU(inplace=True), \r\n",
        "        nn.Linear(args.mlp.hidden_size, args.mlp.projection_size)\r\n",
        "    )\r\n",
        "  def forward(self, x):\r\n",
        "    return self.net(x)\r\n",
        "\r\n",
        "class BYOL(nn.Module):\r\n",
        "  def __init__(self, backbone):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.backbone=backbone\r\n",
        "    self.projector = MLP(resnet.output_dim)\r\n",
        "    self.online_encoder = nn.Sequential(\r\n",
        "        self.backbone, \r\n",
        "        self.projector,\r\n",
        "    )\r\n",
        "    self.predictor = MLP(args.mlp.projection_size)\r\n",
        "    self.target_encoder = copy.deepcopy(self.online_encoder)\r\n",
        "\r\n",
        "  def target_ema(self, k, K, base_tau=args.base_tau):\r\n",
        "    return 1-(1-base_tau)*(math.cos(math.pi*k/K)+1)/2\r\n",
        "\r\n",
        "  def reset_moving_average(self):\r\n",
        "    del self.target_encoder\r\n",
        "    self.target_encoder = copy.deepcopy(self.online_encoder)\r\n",
        "\r\n",
        "  def update_moving_average(self, global_step, max_steps):\r\n",
        "    tau = self.target_ema(global_step, max_steps)\r\n",
        "    for online, target in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\r\n",
        "      target.data = tau*target.data + (1-tau)*online.data\r\n",
        "  \r\n",
        "  def loss_function(self, p, z):\r\n",
        "    p=functional.normalize(p, dim=-1, p=2)\r\n",
        "    z=functional.normalize(z, dim=-1, p=2)\r\n",
        "    return 2 - 2*(p*z).sum(dim=-1)\r\n",
        "\r\n",
        "  def forward(self, x1, x2):\r\n",
        "    z1_online, z2_online = self.online_encoder(x1), self.online_encoder(x2)\r\n",
        "    p1_online, p2_online = self.predictor(z1_online), self.predictor(z2_online)\r\n",
        "    with torch.no_grad():\r\n",
        "      z1_target, z2_target = self.target_encoder(x1), self.target_encoder(x2)\r\n",
        "    \r\n",
        "    loss1, loss2 = self.loss_function(p1_online, z2_target.detach()), self.loss_function(p2_online, z1_target.detach())\r\n",
        "\r\n",
        "    loss = loss1+loss2\r\n",
        "    return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoNT2XuVRa_t"
      },
      "source": [
        "byol = BYOL(resnet)\r\n",
        "byol = byol.to(args.device)\r\n",
        "byol = torch.nn.DataParallel(byol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKix7CVrSenZ"
      },
      "source": [
        "from torch.optim import Adam, SGD\r\n",
        "from torch.optim.optimizer import Optimizer\r\n",
        "\r\n",
        "class LARS(Optimizer):\r\n",
        "  def __init__(self, named_modules, lr, momentum=0.9, trust_coef=1e-3, weight_decay=1.5e-6, exclude_bias_from_adaption=True):\r\n",
        "    defaults = dict(momentum=momentum, lr=lr, weight_decay=weight_decay, trust_coef=trust_coef)\r\n",
        "    parameters = self.exclude_from_model(named_modules, exclude_bias_from_adaption)\r\n",
        "    super(LARS, self).__init__(parameters, defaults)\r\n",
        "\r\n",
        "  @torch.no_grad() \r\n",
        "  def step(self):\r\n",
        "    for group in self.param_groups: # only 1 group in most cases \r\n",
        "      weight_decay = group['weight_decay']\r\n",
        "      momentum = group['momentum']\r\n",
        "      lr = group['lr']\r\n",
        "      trust_coef = group['trust_coef']\r\n",
        "      # print(group['name'])\r\n",
        "      # eps = group['eps']\r\n",
        "      for p in group['params']:\r\n",
        "        # breakpoint()\r\n",
        "        if p.grad is None:\r\n",
        "          continue\r\n",
        "        global_lr = lr\r\n",
        "        velocity = self.state[p].get('velocity', 0)  \r\n",
        "        # if name in self.exclude_from_layer_adaptation:\r\n",
        "        if self._use_weight_decay(group):\r\n",
        "          p.grad.data += weight_decay * p.data \r\n",
        "\r\n",
        "        trust_ratio = 1.0 \r\n",
        "        if self._do_layer_adaptation(group):\r\n",
        "          w_norm = torch.norm(p.data, p=2)\r\n",
        "          g_norm = torch.norm(p.grad.data, p=2)\r\n",
        "          trust_ratio = trust_coef * w_norm / g_norm if w_norm > 0 and g_norm > 0 else 1.0 \r\n",
        "        scaled_lr = global_lr * trust_ratio # trust_ratio is the local_lr \r\n",
        "        next_v = momentum * velocity + scaled_lr * p.grad.data \r\n",
        "        update = next_v\r\n",
        "        p.data = p.data - update \r\n",
        "\r\n",
        "  def _use_weight_decay(self, group):\r\n",
        "    return False if group['name'] == 'exclude' else True\r\n",
        "  def _do_layer_adaptation(self, group):\r\n",
        "    return False if group['name'] == 'exclude' else True\r\n",
        "\r\n",
        "  def exclude_from_model(self, named_modules, exclude_bias_from_adaption=True):\r\n",
        "    base = [] \r\n",
        "    exclude = []\r\n",
        "    for name, module in named_modules:\r\n",
        "      if type(module) in [nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d]:\r\n",
        "        # if isinstance(module, torch.nn.modules.batchnorm._BatchNorm)\r\n",
        "        for name2, param in module.named_parameters():\r\n",
        "          exclude.append(param)\r\n",
        "      else:\r\n",
        "        for name2, param in module.named_parameters():\r\n",
        "          if name2 == 'bias':\r\n",
        "            exclude.append(param)\r\n",
        "          elif name2 == 'weight':\r\n",
        "            base.append(param)\r\n",
        "          else:\r\n",
        "            pass # non leaf modules \r\n",
        "    return [{\r\n",
        "        'name': 'base',\r\n",
        "        'params': base\r\n",
        "        },{\r\n",
        "        'name': 'exclude',\r\n",
        "        'params': exclude\r\n",
        "    }] if exclude_bias_from_adaption == True else [{\r\n",
        "        'name': 'base',\r\n",
        "        'params': base+exclude \r\n",
        "    }]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn6oc9ztTiRR"
      },
      "source": [
        "LARS optimizer is from Github PatrickHua/SimSiam\r\n",
        "\r\n",
        "\r\n",
        "> Link: https://github.com/PatrickHua/SimSiam/blob/main/optimizers/lars_simclr.py\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VonOn4aaUCV2"
      },
      "source": [
        "predictor_prefix = ('module.predictor', 'predictor')\r\n",
        "parameters = [{\r\n",
        "    'name': 'base',\r\n",
        "    'params': [param for name, param in byol.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.base_lr\r\n",
        "},{\r\n",
        "    'name': 'predictor',\r\n",
        "    'params': [param for name, param in byol.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.base_lr\r\n",
        "}]\r\n",
        "if args.optim_name == 'lars':\r\n",
        "  optimizer = LARS(byol.named_modules(), lr=args.base_lr*args.data.batch_size/256, weight_decay=args.weight_decay)\r\n",
        "elif args.optim_name == 'adam':\r\n",
        "  optimizer = Adam(parameters, lr=args.base_lr*args.data.batch_size/256)\r\n",
        "elif args.optim_name == 'sgd':\r\n",
        "  optimizer = SGD(parameters, lr=args.base_lr*args.data.batch_size/256, momentum=0.9)\r\n",
        "else: # default is LARS\r\n",
        "  optimizer = LARS(byol.named_modules(), lr=args.base_lr*args.data.batch_size/256, weight_decay=args.weight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dELIoWzCuZt4"
      },
      "source": [
        "class LR_Scheduler(object):\r\n",
        "  def __init__(self, optimizer, warmup_epochs, warmup_lr, num_epochs, base_lr, final_lr, iter_per_epoch, constant_predictor_lr=False):\r\n",
        "    self.base_lr = base_lr\r\n",
        "    self.constant_predictor_lr = constant_predictor_lr\r\n",
        "    warmup_iter = iter_per_epoch * warmup_epochs\r\n",
        "    warmup_lr_schedule = np.linspace(warmup_lr, base_lr, warmup_iter)\r\n",
        "    decay_iter = iter_per_epoch * (num_epochs - warmup_epochs)\r\n",
        "    cosine_lr_schedule = final_lr+0.5*(base_lr-final_lr)*(1+np.cos(np.pi*np.arange(decay_iter)/decay_iter))\r\n",
        "    \r\n",
        "    self.lr_schedule = np.concatenate((warmup_lr_schedule, cosine_lr_schedule))\r\n",
        "    self.optimizer = optimizer\r\n",
        "    self.iter = 0\r\n",
        "    self.current_lr = 0\r\n",
        "  def step(self):\r\n",
        "    for param_group in self.optimizer.param_groups:\r\n",
        "\r\n",
        "      if self.constant_predictor_lr and param_group['name'] == 'predictor':\r\n",
        "        param_group['lr'] = self.base_lr\r\n",
        "      else:\r\n",
        "        lr = param_group['lr'] = self.lr_schedule[self.iter]\r\n",
        "    \r\n",
        "    self.iter += 1\r\n",
        "    self.current_lr = lr\r\n",
        "    return lr\r\n",
        "  def get_lr(self):\r\n",
        "    return self.current_lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3j31r4xYs36"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "import torch.nn.functional as F \r\n",
        "# code copied from https://colab.research.google.com/github/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb#scrollTo=RI1Y8bSImD7N\r\n",
        "# test using a knn monitor\r\n",
        "def knn_monitor(net, memory_data_loader, test_data_loader, k=200, t=0.1, hide_progress=False):\r\n",
        "  net.eval()\r\n",
        "  classes = len(memory_data_loader.dataset.classes)\r\n",
        "  total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\r\n",
        "  with torch.no_grad():\r\n",
        "    # generate feature bank\r\n",
        "    for data, target in tqdm(memory_data_loader, desc='Feature extracting', leave=False, disable=hide_progress):\r\n",
        "      feature = net(data.cuda(non_blocking=True))\r\n",
        "      feature = F.normalize(feature, dim=1)\r\n",
        "      feature_bank.append(feature)\r\n",
        "    # [D, N]\r\n",
        "    feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\r\n",
        "    # [N]\r\n",
        "    feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\r\n",
        "    # loop test data to predict the label by weighted knn search\r\n",
        "    test_bar = tqdm(test_data_loader, desc='kNN', disable=hide_progress)\r\n",
        "    for data, target in test_bar:\r\n",
        "      data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\r\n",
        "      feature = net(data)\r\n",
        "      feature = F.normalize(feature, dim=1)\r\n",
        "      \r\n",
        "      pred_labels = knn_predict(feature, feature_bank, feature_labels, classes, k, t)\r\n",
        "\r\n",
        "      total_num += data.size(0)\r\n",
        "      total_top1 += (pred_labels[:, 0] == target).float().sum().item()\r\n",
        "      test_bar.set_postfix({'Accuracy':total_top1 / total_num * 100})\r\n",
        "  return total_top1 / total_num * 100\r\n",
        "\r\n",
        "# knn monitor as in InstDisc https://arxiv.org/abs/1805.01978\r\n",
        "# implementation follows http://github.com/zhirongw/lemniscate.pytorch and https://github.com/leftthomas/SimCLR\r\n",
        "def knn_predict(feature, feature_bank, feature_labels, classes, knn_k, knn_t):\r\n",
        "  # compute cos similarity between each feature vector and feature bank ---> [B, N]\r\n",
        "  sim_matrix = torch.mm(feature, feature_bank)\r\n",
        "  # [B, K]\r\n",
        "  sim_weight, sim_indices = sim_matrix.topk(k=knn_k, dim=-1)\r\n",
        "  # [B, K]\r\n",
        "  sim_labels = torch.gather(feature_labels.expand(feature.size(0), -1), dim=-1, index=sim_indices)\r\n",
        "  sim_weight = (sim_weight / knn_t).exp()\r\n",
        "\r\n",
        "  # counts for each class\r\n",
        "  one_hot_label = torch.zeros(feature.size(0) * knn_k, classes, device=sim_labels.device)\r\n",
        "  # [B*K, C]\r\n",
        "  one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\r\n",
        "  # weighted score ---> [B, C]\r\n",
        "  pred_scores = torch.sum(one_hot_label.view(feature.size(0), -1, classes) * sim_weight.unsqueeze(dim=-1), dim=1)\r\n",
        "\r\n",
        "  pred_labels = pred_scores.argsort(dim=-1, descending=True)\r\n",
        "  return pred_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur2YMpd2Vi-U",
        "outputId": "8b236b77-38e6-4cf1-e175-d661a854d8db"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "from collections import defaultdict\r\n",
        "from datetime import datetime\r\n",
        "import os\r\n",
        "\r\n",
        "if not os.path.exists(args.ckpt_dir):\r\n",
        "  os.makedirs(args.ckpt_dir)\r\n",
        "\r\n",
        "tmp_dir = os.path.join(args.ckpt_dir, f\"{args.backbone}\")\r\n",
        "if not os.path.exists(tmp_dir):\r\n",
        "  os.makedirs(tmp_dir)\r\n",
        "tmp_dir = os.path.join(tmp_dir, f\"{args.optim_name}\")\r\n",
        "if not os.path.exists(tmp_dir):\r\n",
        "  os.makedirs(tmp_dir)\r\n",
        "tmp_dir = os.path.join(tmp_dir, f\"{datetime.now().strftime('%m%d%H')}\")\r\n",
        "if not os.path.exists(tmp_dir):\r\n",
        "  os.makedirs(tmp_dir)\r\n",
        "\r\n",
        "writer = SummaryWriter()\r\n",
        "\r\n",
        "global_step = 0\r\n",
        "for epoch in tqdm(range(0, args.num_epochs), desc=f'Training: {epoch}/{args.num_epochs} Accuracy: {main_accuracy}'):\r\n",
        "  metrics = defaultdict(list)\r\n",
        "  \r\n",
        "  for step, ((x1, x2), labels) in enumerate(tqdm(train_loader, desc=f'Step [{step}/{len(train_loader)}]:\\tLoss: {main_loss.item()}')):\r\n",
        "    x1, x2 = x1.cuda(non_blocking=True), x2.cuda(non_blocking=True)\r\n",
        "\r\n",
        "    main_loss = byol(x1, x2)\r\n",
        "    optimizer.zero_grad()\r\n",
        "    main_loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    byol.module.update_moving_average(epoch, args.num_epochs)\r\n",
        "    \r\n",
        "    writer.add_scalar(\"Loss/train_step\", main_loss, global_step)\r\n",
        "    metrics[\"Loss/train\"].append(main_loss.item())\r\n",
        "    global_step += 1\r\n",
        "  \r\n",
        "  for k, v in metrics.items():\r\n",
        "    writer.add_scalar(k, np.array(v).mean(), epoch)\r\n",
        "\r\n",
        "  if args.knn.monitor and epoch % args.knn.interval == 0: \r\n",
        "    main_accuracy = knn_monitor(byol.module.backbone, memory_loader, test_loader, k=min(args.knn.k, len(memory_loader.dataset)), hide_progress=True)\r\n",
        "\r\n",
        "  if epoch%args.checkpoint_epochs == 0:\r\n",
        "    ckpt_path = os.path.join(tmp_dir, f\"{args.name}_{args.optim_name}_{epoch}.pt\")\r\n",
        "    print(f'Saving model at epoch {epoch}')\r\n",
        "    torch.save(resnet.state_dict(), ckpt_path)\r\n",
        "\r\n",
        "ckpt_path = os.path.join(tmp_dir, f\"{args.name}_{args.optim_name}_final.pt\")\r\n",
        "print(f'Saving final model')\r\n",
        "torch.save(resnet.state_dict(), ckpt_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: 0/1 Accuracy: 25.0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Step [3/4]:\tLoss: 4.188074111938477:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Step [3/4]:\tLoss: 4.188074111938477:  50%|█████     | 2/4 [00:00<00:00, 15.78it/s]\u001b[A\n",
            "Step [3/4]:\tLoss: 4.188074111938477: 100%|██████████| 4/4 [00:00<00:00, 15.56it/s]\n",
            "Training: 0/1 Accuracy: 25.0: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model at epoch 0\n",
            "Saving final model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRogCvo2Wu_2"
      },
      "source": [
        "class AverageMeter():\r\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\r\n",
        "    def __init__(self, name, fmt=':f'):\r\n",
        "\r\n",
        "      \r\n",
        "        self.name = name\r\n",
        "        self.fmt = fmt\r\n",
        "        self.log = []\r\n",
        "        self.val = 0\r\n",
        "        self.avg = 0\r\n",
        "        self.sum = 0\r\n",
        "        self.count = 0\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self.log.append(self.avg)\r\n",
        "        self.val = 0\r\n",
        "        self.avg = 0\r\n",
        "        self.sum = 0\r\n",
        "        self.count = 0\r\n",
        "\r\n",
        "    def update(self, val, n=1):\r\n",
        "        self.val = val\r\n",
        "        self.sum += val * n\r\n",
        "        self.count += n\r\n",
        "        self.avg = self.sum / self.count\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\r\n",
        "        return fmtstr.format(**self.__dict__)\r\n",
        "\r\n",
        "def linear_eval(eval_from):\r\n",
        "  eval_train = torchvision.datasets.CIFAR10(\r\n",
        "      root=args.data.dir, \r\n",
        "      train=True, \r\n",
        "      download=False, \r\n",
        "      transform=Transform_single(size=args.data.image_size, train=True), \r\n",
        "      )\r\n",
        "  eval_train_loader = torch.utils.data.DataLoader(\r\n",
        "      eval_train, \r\n",
        "      shuffle=True,\r\n",
        "      batch_size=args.data.batch_size,\r\n",
        "      num_workers=args.data.num_workers,\r\n",
        "      drop_last=True,\r\n",
        "      pin_memory=True,\r\n",
        "      )\r\n",
        "\r\n",
        "  eval_test = torchvision.datasets.CIFAR10(\r\n",
        "      root=args.data.dir, \r\n",
        "      train=False, \r\n",
        "      download=False, \r\n",
        "      transform=Transform_single(size=args.data.image_size, train=False), \r\n",
        "      )\r\n",
        "  eval_test_loader = torch.utils.data.DataLoader(\r\n",
        "      eval_test, \r\n",
        "      shuffle=False,\r\n",
        "      batch_size=args.data.batch_size,\r\n",
        "      num_workers=args.data.num_workers,\r\n",
        "      drop_last=True,\r\n",
        "      pin_memory=True,\r\n",
        "      )\r\n",
        "\r\n",
        "  eval_model = eval(f\"models.{args.backbone}()\")\r\n",
        "  eval_model.output_dim = eval_model.fc.in_features\r\n",
        "  eval_model.fc = torch.nn.Identity()\r\n",
        "  eval_classifier = nn.Linear(in_features=eval_model.output_dim, out_features=10, bias=True).to(args.device)\r\n",
        "\r\n",
        "  ###\r\n",
        "  assert eval_from is not None\r\n",
        "  eval_save_dict = torch.load(eval_from, map_location='cuda')\r\n",
        "  # eval_msg = eval_model.load_state_dict({k[9:]:v for k, v in eval_save_dict['state_dict'].items() if k.startswith('backbone.')}, strict=True)\r\n",
        "  \r\n",
        "  # print(eval_msg)\r\n",
        "  eval_model = eval_model.to(args.device)\r\n",
        "  eval_model = torch.nn.DataParallel(eval_model)\r\n",
        "\r\n",
        "  # if torch.cuda.device_count() > 1: eval_classifier = torch.nn.SyncBatchNorm.convert_sync_batchnorm(eval_classifier)\r\n",
        "  eval_classifier = torch.nn.DataParallel(eval_classifier)\r\n",
        "  # define optimizer 'sgd', eval_classifier, lr=eval_base_lr=30, momentum=eval_optim_momentum-0.9, weight_decay=eval_optim_weight_decay=0\r\n",
        "  predictor_prefix = ('module.predictor', 'predictor')\r\n",
        "  parameters = [{\r\n",
        "      'name': 'base',\r\n",
        "      'params': [param for name, param in eval_classifier.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "      'lr': 30\r\n",
        "  },{\r\n",
        "      'name': 'predictor',\r\n",
        "      'params': [param for name, param in eval_classifier.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "      'lr': 30\r\n",
        "  }]\r\n",
        "  eval_optimizer = torch.optim.SGD(parameters, lr=30, momentum=0.9, weight_decay=0)\r\n",
        "\r\n",
        "  # define lr scheduler\r\n",
        "  eval_lr_scheduler = LR_Scheduler(\r\n",
        "      eval_optimizer,\r\n",
        "      0, 0*args.data.batch_size/256, \r\n",
        "      30, 30*args.data.batch_size/256, 0*args.data.batch_size/256, \r\n",
        "      len(eval_train_loader),\r\n",
        "  )\r\n",
        "\r\n",
        "  eval_loss_meter = AverageMeter(name='Loss')\r\n",
        "  eval_acc_meter = AverageMeter(name='Accuracy')\r\n",
        "\r\n",
        "  # Start training\r\n",
        "  eval_global_progress = tqdm(range(0, 30), desc=f'Evaluating')\r\n",
        "  for epoch in eval_global_progress:\r\n",
        "    eval_loss_meter.reset()\r\n",
        "    eval_model.eval()\r\n",
        "    eval_classifier.train()\r\n",
        "    eval_local_progress = tqdm(eval_train_loader, desc=f'Epoch {epoch}/{30}', disable=True)\r\n",
        "    \r\n",
        "    for idx, (images, labels) in enumerate(eval_local_progress):\r\n",
        "\r\n",
        "      eval_classifier.zero_grad()\r\n",
        "      with torch.no_grad():\r\n",
        "        eval_feature = eval_model(images.to(args.device))\r\n",
        "\r\n",
        "      eval_preds = eval_classifier(eval_feature)\r\n",
        "\r\n",
        "      eval_loss = F.cross_entropy(eval_preds, labels.to(args.device))\r\n",
        "\r\n",
        "      eval_loss.backward()\r\n",
        "      eval_optimizer.step()\r\n",
        "      eval_loss_meter.update(eval_loss.item())\r\n",
        "      eval_lr = eval_lr_scheduler.step()\r\n",
        "      eval_local_progress.set_postfix({'lr':eval_lr, \"loss\":eval_loss_meter.val, 'loss_avg':eval_loss_meter.avg})\r\n",
        "\r\n",
        "  eval_classifier.eval()\r\n",
        "  eval_correct, eval_total = 0, 0\r\n",
        "  eval_acc_meter.reset()\r\n",
        "  for idx, (images, labels) in enumerate(eval_test_loader):\r\n",
        "    with torch.no_grad():\r\n",
        "      eval_feature = eval_model(images.to(args.device))\r\n",
        "      eval_preds = eval_classifier(eval_feature).argmax(dim=1)\r\n",
        "      eval_correct = (eval_preds == labels.to(args.device)).sum().item()\r\n",
        "      eval_acc_meter.update(eval_correct/eval_preds.shape[0])\r\n",
        "  print(f'Accuracy = {eval_acc_meter.avg*100:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QvV0X8xaDri",
        "outputId": "5f8823e4-34e2-410f-eaab-5b23b77f2a2a"
      },
      "source": [
        "if args.eval is not False:\r\n",
        "  linear_eval(ckpt_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 30/30 [1:06:20<00:00, 132.69s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 41.51\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}